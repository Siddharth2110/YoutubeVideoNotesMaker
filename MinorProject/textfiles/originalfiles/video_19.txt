Tip 5: Master the Art of Testing Code
You thought you nailed a particular problem. You identified its problem type, designed
the algorithm for it, verified that the algorithm (with the data structures it uses) will run
in time (and within memory limits) by considering the time (and space) complexity, and
implemented the algorithm, but your solution is still not Accepted (AC).
Depending on the programming contest, you may or may not get credit for solving the
problem partially. In ICPC, you will only get points for a particular problem if your team’s
code solves all the secret test cases for that problem. Other verdicts such as Presentation
Error (PE), Wrong Answer (WA), Time Limit Exceeded (TLE), Memory Limit Exceeded
(MLE), Run Time Error (RTE), etc. do not increase your team’s points. In current IOI
(2010-2012), the subtask scoring system is used. Test cases are grouped into subtasks, usually
simpler variants of the original task with smaller input bounds. You will only be credited
for solving a subtask if your code solves all test cases in it. You are given tokens that you
can use (sparingly) throughout the contest to view the judge’s evaluation of your code.
In either case, you will need to be able to design good, comprehensive and tricky test
cases. The sample input-output given in the problem description is by nature trivial and
therefore usually not a good means for determining the correctness of your code.
Rather than wasting submissions (and thus accumulating time or score penalties) in
ICPC or tokens in IOI, you may want to design tricky test cases for testing your code on
your own machine8. Ensure that your code is able to solve them correctly (otherwise, there
is no point submitting your solution since it is likely to be incorrect—unless you want to test
the test data bounds).
Some coaches encourage their students to compete with each other by designing test
cases. If student A’s test cases can break student B’s code, then A will get bonus points.
You may want to try this in your team training :).
Here are some guidelines for designing good test cases from our experience.
These are typically the steps that have been taken by problem authors.
1. Your test cases should include the sample test cases since the sample output is guaranteed
to be correct. Use ‘fc’ in Windows or ‘diff’ in UNIX to check your code’s output
(when given the sample input) against the sample output. Avoid manual comparison
as humans are prone to error and are not good at performing such tasks, especially
for problems with strict output formats (e.g. blank line between test cases versus after
every test cases). To do this, copy and paste the sample input and sample output
from the problem description, then save them to files (named as ‘input’ and ‘output’
or anything else that is sensible). Then, after compiling your program (let’s assume
the executable’s name is the ‘g++’ default ‘a.out’), execute it with an I/O redirection:
‘./a.out < input > myoutput’. Finally, execute ‘diff myoutput output’ to
highlight any (potentially subtle) differences, if any exist.
2. For problems with multiple test cases in a single run (see Section 1.3.2), you should
include two identical sample test cases consecutively in the same run. Both must
output the same known correct answers. This helps to determine if you have forgotten
to initialize any variables—if the first instance produces the correct answer but the
second one does not, it is likely that you have not reset your variables.
3. Your test cases should include tricky corner cases. Think like the problem author and
try to come up with the worst possible input for your algorithm by identifying cases that are ‘hidden’ or implied within the problem description. These cases are usually
included in the judge’s secret test cases but not in the sample input and output. Corner
cases typically occur at extreme values such as N = 0, N = 1, negative values, large
final (and/or intermediate) values that does not fit 32-bit signed integer, etc.
4. Your test cases should include large cases. Increase the input size incrementally up to
the maximum input bounds stated in the problem description. Use large test cases with
trivial structures that are easy to verify with manual computation and large random
test cases to test if your code terminates in time and still produces reasonable output
(since the correctness would be difficult to verify here). Sometimes your program may
work for small test cases, but produces wrong answer, crashes, or exceeds the time
limit when the input size increases. If that happens, check for overflows, out of bound
errors, or improve your algorithm.